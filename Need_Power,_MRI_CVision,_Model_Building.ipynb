{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mPI1Q1gg8vLZ",
        "fHJlgSN-8yWI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JRQplJX3MlzB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import layers\n",
        "\n",
        "import util\n",
        "from public_tests import *\n",
        "from test_utils import *\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Dir = \"/content/drive/MyDrive/MRI_CVision_Data/imagesTr/\"\n",
        "Labels_Dir = \"/content/drive/MyDrive/MRI_CVision_Data/labelsTr/\""
      ],
      "metadata": {
        "id": "uHOUK02wOz1K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patches"
      ],
      "metadata": {
        "id": "mPI1Q1gg8vLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# due to limited processing power, \"patches\" or \"sub-volumes\" if shape (160, 160, 16) are required\n",
        "# patches have to be at leadt 5% tumor\n",
        "\n",
        "def get_sub_volume(image, label,\n",
        "                   orig_x = 240, orig_y = 240, orig_z = 155,\n",
        "                   output_x = 160, output_y = 160, output_z = 16,\n",
        "                   num_classes = 4, max_tries = 1000,\n",
        "                   background_threshold=0.95):\n",
        "\n",
        "    X = None\n",
        "    y = None\n",
        "    tries = 0\n",
        "\n",
        "    while tries < max_tries:\n",
        "        start_x = np.random.randint(orig_x-output_x+1)\n",
        "        start_y = np.random.randint(orig_y-output_y+1)\n",
        "        start_z = np.random.randint(orig_z-output_z+1)\n",
        "\n",
        "        y = label[start_x: start_x + output_x,\n",
        "                  start_y: start_y + output_y,\n",
        "                  start_z: start_z + output_z]\n",
        "        y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "        bgrd_ratio = np.sum(y[:, :, :, 0])/(output_x * output_y * output_z)\n",
        "        tries += 1\n",
        "        if bgrd_ratio < background_threshold:\n",
        "            X = np.copy(image[start_x: start_x + output_x,\n",
        "                              start_y: start_y + output_y,\n",
        "                              start_z: start_z + output_z, :])\n",
        "            X =  np.transpose(X, (3, 0, 1, 2))\n",
        "            y =  np.transpose(y, (3, 0, 1, 2))\n",
        "            y = y[1:, :, :, :]\n",
        "\n",
        "            return X, y\n",
        "\n",
        "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
      ],
      "metadata": {
        "id": "rASZQfQB1JgU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization"
      ],
      "metadata": {
        "id": "fHJlgSN-8yWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(image):\n",
        "  standardized_image = np.zeros(image.shape)\n",
        "  for c in range(image.shape[0]):\n",
        "    for z in range(image.shape[3]):\n",
        "      image_slice = image[c,:,:,z]\n",
        "      centered = image_slice - np.mean(image_slice)\n",
        "      if np.std(centered) != 0:\n",
        "        centered_scaled = image_slice/np.std(image_slice)\n",
        "      standardized_image[c, :, :, z] = centered_scaled\n",
        "\n",
        "    return standardized_image"
      ],
      "metadata": {
        "id": "-Xk4m3zS83Pu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3D U-Net Model Creation"
      ],
      "metadata": {
        "id": "5cJ1ZxUZ-w_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), epsilon=0.00001):\n",
        "    intersection = K.sum(y_true * y_pred, axis=axis)\n",
        "    sum_true = K.sum(y_true, axis=axis)\n",
        "    sum_pred = K.sum(y_pred, axis=axis)\n",
        "    dice_numerator = (2 * intersection) + epsilon\n",
        "    dice_denominator = sum_true + sum_pred + epsilon\n",
        "    dice_coefficient = (K.mean((dice_numerator) / (dice_denominator)))\n",
        "    return dice_coefficient\n",
        "\n",
        "\n",
        "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), epsilon=0.00001):\n",
        "    intersection = K.sum(y_true * y_pred, axis=axis)\n",
        "    sum_true = K.sum(y_true * y_true, axis=axis)\n",
        "    sum_pred = K.sum(y_pred * y_pred, axis=axis)\n",
        "    dice_numerator = (2 * intersection) + epsilon\n",
        "    dice_denominator = sum_true + sum_pred + epsilon\n",
        "    dice_loss = 1 - (K.mean((dice_numerator) / (dice_denominator)))\n",
        "    return dice_loss\n",
        "\n",
        "\n",
        "\n",
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=None, padding='same',\n",
        "                             strides=(1, 1, 1), instance_normalization=False):\n",
        "    layer = tf.keras.layers.Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
        "        input_layer)\n",
        "    if activation is None:\n",
        "        return keras.layers.Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)\n",
        "\n",
        "\n",
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2), strides=(2, 2, 2), deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return tf.keras.layers.Deconvolution3D(filters=n_filters, kernel_size=kernel_size, strides=strides)\n",
        "    else:\n",
        "        return tf.keras.layers.UpSampling3D(size=pool_size)\n",
        "\n",
        "\n",
        "\n",
        "def unet_model_3d(loss_function, input_shape=(4, 160, 160, 16), pool_size=(2, 2, 2), n_labels=3, initial_learning_rate=0.00001, deconvolution=False,\n",
        "                  depth=4, n_base_filters=32, include_label_wise_dice_coefficients=False, metrics=[], batch_normalization=False, activation_name=\"sigmoid\"):\n",
        "\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "    current_layer = inputs\n",
        "    levels = list()\n",
        "\n",
        "    # add levels with max pooling\n",
        "    for layer_depth in range(depth):\n",
        "        layer1 = create_convolution_block(input_layer=current_layer, n_filters=n_base_filters * (2 ** layer_depth), batch_normalization=batch_normalization)\n",
        "        layer2 = create_convolution_block(input_layer=layer1, n_filters=n_base_filters * (2 ** layer_depth) * 2, batch_normalization=batch_normalization)\n",
        "        if layer_depth < depth - 1:\n",
        "            current_layer = keras.layers.MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "            levels.append([layer1, layer2, current_layer])\n",
        "        else:\n",
        "            current_layer = layer2\n",
        "            levels.append([layer1, layer2])\n",
        "\n",
        "    # add levels with up-convolution or up-sampling\n",
        "    for layer_depth in range(depth - 2, -1, -1):\n",
        "        up_convolution = get_up_convolution(pool_size=pool_size, deconvolution=deconvolution, n_filters=current_layer.shape[1])(current_layer)\n",
        "        concat = tf.concat([up_convolution, levels[layer_depth][1]], axis=1)\n",
        "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1].shape[1], input_layer=concat, batch_normalization=batch_normalization)\n",
        "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1].shape[1], input_layer=current_layer, batch_normalization=batch_normalization)\n",
        "\n",
        "    final_convolution = tf.keras.layers.Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
        "    act = keras.layers.Activation(activation_name)(final_convolution)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate), loss=loss_function, metrics=metrics)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])"
      ],
      "metadata": {
        "id": "ozaLONqN-wjK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/MyDrive/MRI_CVision_Data/processed/\"\n",
        "\n",
        "with open(base_dir + \"config.json\") as json_file:\n",
        "    config = json.load(json_file)\n",
        "\n",
        "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
        "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
        "\n",
        "\n",
        "model.fit_generator(generator=train_generator, steps_per_epoch=20, epochs=10, use_multiprocessing=True,\n",
        "                    validation_data=valid_generator, validation_steps=20)"
      ],
      "metadata": {
        "id": "JMDYQ5KwSK6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3D U-Net Model Training Alternative"
      ],
      "metadata": {
        "id": "A-C1gLe7hJHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open(\"/content/drive/MyDrive/MRI_CVision_Data/dataset.json\") as json_file:\n",
        "    config = json.load(json_file)\n",
        "\n",
        "\n",
        "# Function to load and preprocess image and label data\n",
        "def load_and_preprocess_data(image_path, label_path):\n",
        "    image_data = nib.load(image_path).get_fdata()\n",
        "    label_data = nib.load(label_path).get_fdata()\n",
        "\n",
        "    # Perform preprocessing as needed\n",
        "\n",
        "    return image_data, label_data\n",
        "\n",
        "\n",
        "\n",
        "# Prepare training and testing data\n",
        "train_data = []\n",
        "test_data = []\n",
        "for sample in config['training']:\n",
        "    image_path = \"/content/drive/MyDrive/MRI_CVision_Data\" + sample['image'][1:]\n",
        "    label_path = \"/content/drive/MyDrive/MRI_CVision_Data\" + sample['label'][1:]\n",
        "    image_data, label_data = load_and_preprocess_data(image_path, label_path)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_image, test_image, train_label, test_label = train_test_split(image_data, label_data, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_data.append((train_image, train_label))\n",
        "    test_data.append((test_image, test_label))\n",
        "\n",
        "# Convert training and testing data to NumPy arrays\n",
        "train_images = np.array([sample[0] for sample in train_data])\n",
        "train_labels = np.array([sample[1] for sample in train_data])\n",
        "test_images = np.array([sample[0] for sample in test_data])\n",
        "test_labels = np.array([sample[1] for sample in test_data])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x=train_images, y=train_labels, epochs=10, batch_size=10)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "test_loss, test_accuracy = model.evaluate(x=test_images, y=test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "'''"
      ],
      "metadata": {
        "id": "RevdCG0BfLQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}